{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is tutorial using TabNetClassifier \n",
    "\n",
    "    This includes Cross Validation test and Hyper parameter tuning\n",
    "    this code is only for classifcation at the moment (soon I will make tutorial for regressor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries\n",
    "\n",
    "    set target feature and unused function.\n",
    "    All features need to be float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch import tensor \n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import itertools\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "train_data= pd.read_csv('./data/train.ct.csv')\n",
    "test_data= pd.read_csv('./data/test.ct.csv')\n",
    "target ='sex'\n",
    "unused_feat = ['Set', 'subjectkey', 'race.ethnicity', 'abcd_site', 'Unnamed: 0', 'fsqc_qc.y', 'kflod']\n",
    "Num_FOLDS  = 5\n",
    "# the number of feature that you want to show \n",
    "Num_feat = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preproecessing: fillna as 0, set kflod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproecessing (train_data, test_data, NUM_FOLDS):\n",
    "    test_data_processed= test_data.fillna(0).reset_index(drop=True)\n",
    "    train_data_processed = train_data.fillna(0).reset_index(drop=True)\n",
    "    \n",
    "    test_data_processed[\"kfold\"] = -1\n",
    "\n",
    "    train_data_processed[\"kfold\"] = -1\n",
    "\n",
    "    train_data_processed = train_data_processed.sample(frac=1,random_state=2020).reset_index(drop=True)\n",
    "\n",
    "    kf = KFold(n_splits=NUM_FOLDS)\n",
    "\n",
    "    for fold, (trn_, val_) in enumerate(kf.split(X=train_data_processed, y=train_data_processed)):\n",
    "        train_data_processed.loc[val_, 'kfold'] = fold\n",
    "    print(\"done preprocessing\")\n",
    "    return train_data_processed, test_data_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function of finding best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented\n",
    "import torch\n",
    "import itertools\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def find_bestpar(X_train, Y_train, X_valid, Y_valid, X_test, Y_test):\n",
    "    # Store maximum auc\n",
    "    max_auc= 0\n",
    "    # Store maximum hypterparameter set\n",
    "    max_hy = []\n",
    "    # define hyperparameter space\n",
    "    \"\"\"\n",
    "    n_ = [4,8,16]\n",
    "    lr_ = [2e-2, 1e-2, 5e-3, 2e-3, 1e-3, 1e-4]\n",
    "    w_ = [0.01, 0.001, 0.0001]\n",
    "    g_ = [0.95, 0.99, 0.9]\n",
    "    ss_ = [10, 20, 30]\n",
    "    # Orginal hyperparameter space \n",
    "    \"\"\"\n",
    "    # define hyperparameter space (quick version)\n",
    "    n_ = [4]\n",
    "    lr_ = [2e-2]\n",
    "    w_ = [0.01]\n",
    "    g_ = [0.95]\n",
    "    ss_ = [10, 20]\n",
    "    \n",
    "    all_ = [n_, lr_, w_, g_, ss_]\n",
    "    h_space = [s for s in itertools.product(*all_)]\n",
    "    \n",
    "    for hy in tqdm(h_space):\n",
    "        clf = TabNetClassifier(n_a = hy[0],\n",
    "                               n_d = hy[0],\n",
    "                               optimizer_params = dict(lr=hy[1], weight_decay=hy[2]),\n",
    "                               scheduler_params={\"step_size\":hy[4], \"gamma\":hy[3]},\n",
    "                               scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                               verbose=0\n",
    "                               )\n",
    "        clf.fit(X_train, Y_train, X_valid, Y_valid, patience=10, batch_size=256, max_epochs=200)\n",
    "        #clf.fit(X_train, Y_train, X_valid, Y_valid, patience=50, batch_size=256, max_epochs=200) (Recommended)\n",
    "        preds_acc = clf.predict(X_test)\n",
    "        preds_prob = clf.predict_proba(X_test)\n",
    "        test_auc = roc_auc_score(y_score=preds_prob[:,1], y_true=Y_test)\n",
    "        test_acc = accuracy_score(preds_acc, Y_test)\n",
    "        print(\"--------Test auc: {} Test acc:{}-------------\".format(test_auc, test_acc) )\n",
    "        if test_auc>max_auc:\n",
    "            max_hy = hy\n",
    "            max_auc = test_auc\n",
    "    return max_hy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do it with best hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestpar_tuning(X_train, Y_train, X_valid, Y_valid, X_test, Y_test, max_hy):\n",
    " \n",
    "    hy = max_hy\n",
    "    clf = TabNetClassifier(n_a = hy[0],\n",
    "                           n_d = hy[0],\n",
    "                           optimizer_params = dict(lr=hy[1], weight_decay=hy[2]),\n",
    "                           scheduler_params={\"step_size\":hy[4], \"gamma\":hy[3]},\n",
    "                           scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                           verbose=0\n",
    "                               )\n",
    "    clf.fit(X_train, Y_train, X_valid, Y_valid, patience=50, batch_size=256, max_epochs=200)\n",
    "    preds_acc = clf.predict(X_test)\n",
    "    preds_prob = clf.predict_proba(X_test)\n",
    "    test_auc = roc_auc_score(y_score=preds_prob[:,1], y_true=Y_test)\n",
    "    test_acc = accuracy_score(preds_acc, Y_test)\n",
    "    print(\"Max hy:\" ,hy)\n",
    "    print(\"FINAL TEST SCORE(max) test auc: {} test acc: {}\".format(test_auc, test_acc))\n",
    "    return test_auc, clf\n",
    "    \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find importance feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(Num_feat, clf, test_data_processed, features):\n",
    "    importance =clf.feature_importances_\n",
    "    plt.plot(importance)\n",
    "    plt.show()\n",
    "    labels_importance=importance.argsort()[::-1]\n",
    "\n",
    "    importance_sort = np.sort(importance)[::-1]\n",
    "\n",
    "    feat_name_sort=test_data_processed[features].columns[labels_importance]\n",
    "    important_features = pd.DataFrame() \n",
    "\n",
    "\n",
    "    for i in range (Num_feat):\n",
    "        feature = pd.DataFrame([[feat_name_sort[i],importance_sort[i]]], columns = ['feature name', 'ratio'])\n",
    "        important_features=pd.concat([important_features,feature])\n",
    "\n",
    "    print(important_features.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define run(find best par, learn with best par, show feature) function \n",
    "    set X_test, Y_test, X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run(train_data_processed, test_data_processed, fold, Num_feat, features):\n",
    "    X_test = test_data_processed[features].values\n",
    "    Y_test = test_data_processed[target].values\n",
    "\n",
    "    df_train = train_data_processed[train_data_processed.kfold != fold]\n",
    "    df_valid = train_data_processed[train_data_processed.kfold == fold]\n",
    "    \n",
    "    X_train = df_train[features].values\n",
    "    Y_train = df_train[target].values\n",
    "    \n",
    "    X_valid = df_valid[features].values\n",
    "    Y_valid = df_valid[target].values\n",
    "    \n",
    "    y_oof = np.zeros((df_valid.shape[0],len(target)))   # Out of folds validation\n",
    "    \n",
    "    print(\"--------Training Begining for fold {}-------------\".format(fold+1))\n",
    "    n_ = [4,8,16]\n",
    "    lr_ = [2e-2, 1e-2, 5e-3, 2e-3, 1e-3, 1e-4]\n",
    "    w_ = [0.01, 0.001, 0.0001]\n",
    "    g_ = [0.95, 0.99, 0.9]\n",
    "    ss_ = [10, 20, 30]\n",
    "    all_ = [n_, lr_, w_, g_, ss_]\n",
    "    h_space = [s for s in itertools.product(*all_)]\n",
    "    # Start training\n",
    "    max_hy = find_bestpar(X_train, Y_train, X_valid, Y_valid, X_test, Y_test)\n",
    "    print(\"Found maximum hyperparmeter, now work with that\")\n",
    "    test_auc, clf = bestpar_tuning(X_train, Y_train, X_valid, Y_valid, X_test, Y_test, max_hy)\n",
    "    \n",
    "    feature(Num_feat, clf, test_data_processed, features)\n",
    "    \n",
    "    return test_auc\n",
    "    \n",
    "    # VISUALIZTION\n",
    "    #plt.figure(figsize=(12,6))\n",
    "    #plt.plot(model.history['train']['loss'])\n",
    "    #plt.plot(model.history['valid']['loss'])\n",
    "    \n",
    "    #Plotting Metric\n",
    "    #plt.plot([-x for x in model.history['train']['metric']])\n",
    "    #plt.plot([-x for x in model.history['valid']['metric']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definde function for Cross Validation test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparametertuning_CV (train_data, test_data, target, unused_feat, Num_FOLDS, Num_feat):\n",
    "    CV_auc_all = []\n",
    "    train_data_processed, test_data_processed = preproecessing (train_data, test_data, Num_FOLDS)\n",
    "    \n",
    "    features = [ col for col in train_data_processed.columns if col not in unused_feat + [target]] \n",
    "    \n",
    "    for i in range(Num_FOLDS):\n",
    "        test_auc = run(train_data_processed, test_data_processed, i, Num_feat, features)\n",
    "        print (\"--------Test auc: {} for fold {}-------------\".format(test_auc, i+1))\n",
    "        print (\"---------------------------------------------\")\n",
    "        CV_auc_all.append(test_auc)\n",
    "    print(CV_auc_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally! you can do hyperparametertuning with Cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done preprocessing\n",
      "--------Training Begining for fold 1-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0359d148ed784a379dda82333b185b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "--------Test auc: 0.842874614540323 Test acc:0.7301992846193153-------------\n",
      "Device used : cuda\n",
      "--------Test auc: 0.842874614540323 Test acc:0.7301992846193153-------------\n",
      "\n",
      "Device used : cuda\n",
      "Max hy: (4, 0.02, 0.01, 0.95, 10)\n",
      "FINAL TEST SCORE(max) test auc: 0.8480823707730099 test acc: 0.7496167603474706\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              feature name     ratio\n",
      "0  con_L.CACG_L.RACG_count  0.192914\n",
      "1   con_L.RACG_R.LOG_count  0.151109\n",
      "2    con_L.IPG_R.STG_count  0.147737\n",
      "3   con_L.PCAL_L.SFG_count  0.057283\n",
      "4    con_R.HI_R.PoCG_count  0.054463\n",
      "--------Test auc: 0.8480823707730099 for fold 1-------------\n",
      "---------------------------------------------\n",
      "--------Training Begining for fold 2-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4320d4f5064dee9487bf4aa854a72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_data= pd.read_csv('./data/train.ct.csv')\n",
    "test_data= pd.read_csv('./data/test.ct.csv')\n",
    "target ='sex'\n",
    "unused_feat = ['Set', 'subjectkey', 'race.ethnicity', 'abcd_site', 'Unnamed: 0', 'fsqc_qc.y', 'kflod']\n",
    "Num_FOLDS  = 5\n",
    "# the number of feature that you want to show \n",
    "Num_feat = 5\n",
    "\n",
    "\"\"\"    \n",
    "\n",
    "hyperparametertuning_CV (train_data, test_data, target, unused_feat, Num_FOLDS, Num_feat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
